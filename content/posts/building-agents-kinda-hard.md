+++
title = 'Building Agents is kinda hard'
date = 2024-05-07T18:25:17Z
summary = "This post discusses the challenges with developing an agentic blog post writer using LangChain, a framework for complex LLM tasks, and the search for alternatives, including exploring the Ollama Python library."
+++

## A Journey of Trial and Error

As I've been working on developing an agentic blog post writer, I must admit that the journey has been more challenging than anticipated. In this post, I'll share my experiences with using LangChain, a popular framework for developing agents and accomplishing complex LLM tasks.

### The Challenges of LangChain

Initially, I was excited to try out LangChain, but soon realized that it's still in development and undergoing significant refactoring changes. The documentation is still referencing old versions, making it unreliable for my purposes. Despite these challenges, I did have some success with LangChain, such as chaining a prompt, an LLM, and output parser together to generate some output. Additionally, I was able to perform RAG (Retrieval Augmented Generation) on web content and obtain some results.

#### Unpredictability and Consistency

However, my experience with LangChain was marked by unpredictability. The LLM I'm using, initially impressive, proved difficult to tame and control. When the output is inconsistent, the agent may behave in unpredictable ways, which is unacceptable for developing a reliable agentic blog post writer.

#### The Search for Alternatives

It's possible that I'm overlooking something important or that there are other frameworks better suited for this purpose. I don't know! For now, I'll explore the simple Ollama Python library to see if it can get me anywhere. Perhaps this will lead me down a more fruitful path.

### Next Steps: Exploring Ollama

As I continue my journey to develop an agentic blog post writer, I'm excited to explore the Ollama Python library. Will it prove to be the solution I've been searching for? Only time will tell. In my next update, I'll share my experiences and insights with using plain Ollama. Stay tuned!
